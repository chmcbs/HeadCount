{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48c621b8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a5f4409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa8c25b",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "854f7f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from disk...\n",
      "✓ Loaded 1096 examples from disk\n"
     ]
    }
   ],
   "source": [
    "# Define path\n",
    "dataset_path = Path(\"./data\")\n",
    "\n",
    "# Check if dataset is saved to disk\n",
    "if dataset_path.exists() and (dataset_path / \"dataset_dict.json\").exists():\n",
    "    print(\"Loading dataset from disk...\")\n",
    "    dataset = load_from_disk(str(dataset_path))\n",
    "    print(f\"✓ Loaded {len(dataset['labelled'])} examples from disk\")\n",
    "    \n",
    "# If not on disk, check if dataset variable exists in memory\n",
    "elif 'dataset' in globals() and dataset is not None:\n",
    "    print(\"Dataset variable found in memory, saving to disk...\")\n",
    "    dataset.save_to_disk(str(dataset_path))\n",
    "    print(f\"✓ Saved {len(dataset['labelled'])} examples to disk\")\n",
    "    \n",
    "# Otherwise, load from HuggingFace and save\n",
    "else:\n",
    "    print(\"Loading dataset from HuggingFace...\")\n",
    "    dataset = load_dataset(\"GlobalWheat/GWFSS_v1.0\")\n",
    "    print(f\"✓ Loaded {len(dataset['labelled'])} examples from HuggingFace\")\n",
    "    \n",
    "    print(\"Saving dataset to disk...\")\n",
    "    dataset.save_to_disk(str(dataset_path))\n",
    "    print(f\"✓ Saved dataset to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58af55ca",
   "metadata": {},
   "source": [
    "### Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c886cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded class counts from cache\n",
      "✓ Created stratification labels\n"
     ]
    }
   ],
   "source": [
    "# Define class mapping and class counts path\n",
    "class_counts_path = Path(\"./cache/class_counts.json\")\n",
    "rgb_to_class = {\n",
    "    (0, 0, 0): 0,              # Background (Black)\n",
    "    (214, 255, 50): 1,         # Leaf (Yellow-green)\n",
    "    (50, 132, 255): 2,         # Stem (Blue)\n",
    "    (50, 255, 132): 3,         # Head (Cyan-green)\n",
    "}\n",
    "\n",
    "# Load class counts if available\n",
    "if class_counts_path.exists():\n",
    "    with open(class_counts_path, 'r') as f:\n",
    "        class_counts_dict = json.load(f)\n",
    "    class_counts = defaultdict(list, {int(k): v for k, v in class_counts_dict.items()})\n",
    "    print(f\"✓ Loaded class counts from cache\")\n",
    "else:\n",
    "    print(\"⚠ Class counts not found. Please run the EDA notebook first.\")\n",
    "\n",
    "# Define function to get the dominant class of an image\n",
    "def get_dominant_class(image_idx):\n",
    "    counts = [class_counts[class_id][image_idx] for class_id in range(4)]\n",
    "    return np.argmax(counts)\n",
    "\n",
    "# Create a list containing the dominant class label for each image (0-3)\n",
    "stratify_labels = [get_dominant_class(i) for i in range(len(dataset[\"labelled\"]))]\n",
    "print(f\"✓ Created stratification labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e52448",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa958750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created stratified splits:\n",
      "  Train: 767 examples (70.0%)\n",
      "  Val:   164 examples (15.0%)\n",
      "  Test:  165 examples (15.1%)\n"
     ]
    }
   ],
   "source": [
    "# Split 1: Train/ValTest (70:30)\n",
    "train_indices, valtest_indices = train_test_split(\n",
    "    range(len(dataset[\"labelled\"])),\n",
    "    test_size=0.3,\n",
    "    stratify=stratify_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split 2: Val/Test (50:50)\n",
    "valtest_labels = [stratify_labels[i] for i in valtest_indices]\n",
    "val_indices, test_indices = train_test_split(\n",
    "    valtest_indices,\n",
    "    test_size=0.5,  # 50% of ValTest = 15% of total\n",
    "    stratify=valtest_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create splits\n",
    "train_split = dataset[\"labelled\"].select(train_indices)\n",
    "val_split = dataset[\"labelled\"].select(val_indices)\n",
    "test_split = dataset[\"labelled\"].select(test_indices)\n",
    "\n",
    "print(f\"✓ Created stratified splits:\")\n",
    "print(f\"  Train: {len(train_split)} examples ({100*len(train_split)/len(dataset['labelled']):.1f}%)\")\n",
    "print(f\"  Val:   {len(val_split)} examples ({100*len(val_split)/len(dataset['labelled']):.1f}%)\")\n",
    "print(f\"  Test:  {len(test_split)} examples ({100*len(test_split)/len(dataset['labelled']):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4300954c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Dataset dominant class distribution:\n",
      "  Background: 301 (27.5%)\n",
      "  Leaf: 772 (70.4%)\n",
      "  Stem: 0 (0.0%)\n",
      "  Head: 23 (2.1%)\n",
      "\n",
      "Train dominant class distribution:\n",
      "  Background: 211 (27.5%)\n",
      "  Leaf: 540 (70.4%)\n",
      "  Stem: 0 (0.0%)\n",
      "  Head: 16 (2.1%)\n",
      "\n",
      "Val dominant class distribution:\n",
      "  Background: 45 (27.4%)\n",
      "  Leaf: 116 (70.7%)\n",
      "  Stem: 0 (0.0%)\n",
      "  Head: 3 (1.8%)\n",
      "\n",
      "Test dominant class distribution:\n",
      "  Background: 45 (27.3%)\n",
      "  Leaf: 116 (70.3%)\n",
      "  Stem: 0 (0.0%)\n",
      "  Head: 4 (2.4%)\n"
     ]
    }
   ],
   "source": [
    "# Define function to check dominant class distribution in a split\n",
    "def check_stratification(split_name, split_indices):\n",
    "    split_labels = [stratify_labels[i] for i in split_indices]\n",
    "    class_names = ['Background', 'Leaf', 'Stem', 'Head']\n",
    "    print(f\"\\n{split_name} dominant class distribution:\")\n",
    "    for class_id, class_name in enumerate(class_names):\n",
    "        count = sum(1 for label in split_labels if label == class_id)\n",
    "        pct = 100 * count / len(split_labels)\n",
    "        print(f\"  {class_name}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "# Check the dominant class distribution of the full dataset        \n",
    "check_stratification(\"Full Dataset\", range(len(dataset[\"labelled\"])))\n",
    "\n",
    "# Check the dominant class distribution of each split\n",
    "check_stratification(\"Train\", train_indices)\n",
    "check_stratification(\"Val\", val_indices)\n",
    "check_stratification(\"Test\", test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b7eebb",
   "metadata": {},
   "source": [
    "### PyTorch Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "840c97f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ImageNet normalisation constants (for pretrained ResNet)\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Create a custom class for the segmentation transforms\n",
    "class SegmentationTransform:\n",
    "    def __init__(self, image_size=512, augment=False):\n",
    "        self.image_size = image_size\n",
    "        self.augment = augment\n",
    "    \n",
    "    def __call__(self, image, mask):\n",
    "        # Resize image and mask to the same size\n",
    "        resize_image = transforms.Resize((self.image_size, self.image_size), \n",
    "                                   interpolation=transforms.InterpolationMode.BILINEAR) # Smoothing for image\n",
    "        resize_mask = transforms.Resize((self.image_size, self.image_size),\n",
    "                                        interpolation=transforms.InterpolationMode.NEAREST) # Nearest neighbour for mask\n",
    "        \n",
    "        image = resize_image(image)\n",
    "        mask = resize_mask(mask)\n",
    "        \n",
    "        # Augment training data (improves generalisation and reduces overfitting)\n",
    "        if self.augment:\n",
    "            # Random horizontal flip\n",
    "            if np.random.random() > 0.5:\n",
    "                image = transforms.functional.hflip(image)\n",
    "                mask = transforms.functional.hflip(mask)\n",
    "            \n",
    "            # Random rotation\n",
    "            angle = np.random.uniform(-15, 15)\n",
    "            image = transforms.functional.rotate(image, angle, \n",
    "                                                 interpolation=transforms.InterpolationMode.BILINEAR) # Smoothing for image\n",
    "            mask = transforms.functional.rotate(mask, angle,\n",
    "                                                interpolation=transforms.InterpolationMode.NEAREST) # Nearest neighbour for mask\n",
    "            \n",
    "            # Random colour jitter\n",
    "            color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
    "            image = color_jitter(image)\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "# Create a custom class for the GWFSS dataset\n",
    "class GWFSSDataset(Dataset):\n",
    "    def __init__(self, dataset_split, transform=None):\n",
    "        self.dataset = dataset_split\n",
    "        self.transform = transform\n",
    "        self.rgb_to_class = {\n",
    "            (0, 0, 0): 0,\n",
    "            (214, 255, 50): 1,\n",
    "            (50, 132, 255): 2,\n",
    "            (50, 255, 132): 3,\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.dataset[idx]\n",
    "        image = example['image']\n",
    "        mask_rgb = example['mask']\n",
    "        mask_array = np.array(mask_rgb)\n",
    "\n",
    "        # Create an empty array with the same dimensions as the mask to store the class labels\n",
    "        mask = np.zeros((mask_array.shape[0], mask_array.shape[1]), dtype=np.int64)\n",
    "\n",
    "        # For each RGB colour in the mapping, set the corresponding pixels in the mask to the class label\n",
    "        for rgb_tuple, class_id in self.rgb_to_class.items():\n",
    "            mask[(mask_array == rgb_tuple).all(axis=2)] = class_id\n",
    "    \n",
    "        # Convert the mask array to a greyscale PIL Image\n",
    "        mask = Image.fromarray(mask, mode='L')\n",
    "    \n",
    "        # Transform image and mask (done together to maintain alignment)\n",
    "        if self.transform:\n",
    "            image, mask = self.transform(image, mask)\n",
    "    \n",
    "        # Convert to tensors\n",
    "        image = transforms.ToTensor()(image)\n",
    "        mask = torch.from_numpy(np.array(mask)).long()\n",
    "    \n",
    "        # Normalise image\n",
    "        normalize = transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "        image = normalize(image)\n",
    "    \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2921f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created PyTorch datasets:\n",
      "  Train: 767 examples\n",
      "  Val: 164 examples\n",
      "  Test: 165 examples\n"
     ]
    }
   ],
   "source": [
    "# Create transforms\n",
    "train_transform = SegmentationTransform(image_size=512, augment=True)\n",
    "val_transform = SegmentationTransform(image_size=512, augment=False)\n",
    "test_transform = SegmentationTransform(image_size=512, augment=False)\n",
    "\n",
    "# Use transforms to create datasets\n",
    "train_dataset = GWFSSDataset(train_split, transform=train_transform)\n",
    "val_dataset = GWFSSDataset(val_split, transform=val_transform)\n",
    "test_dataset = GWFSSDataset(test_split, transform=test_transform)\n",
    "\n",
    "print(f\"✓ Created PyTorch datasets:\")\n",
    "print(f\"  Train: {len(train_dataset)} examples\")\n",
    "print(f\"  Val: {len(val_dataset)} examples\")\n",
    "print(f\"  Test: {len(test_dataset)} examples\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
